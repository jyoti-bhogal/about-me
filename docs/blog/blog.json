[
  {
    "path": "blog/2024-10-26_pycon_india_2024/",
    "title": "Insights from My Experience at PyCon India 2024",
    "description": "Insights from the annual 4-day Python conference",
    "author": [
      {
        "name": "Jyoti Bhogal",
        "url": "https://jyoti-bhogal.github.io/about-me/"
      }
    ],
    "date": "2024-10-26",
    "categories": [
      "Python",
      "Conference",
      "Talk",
      "India",
      "Open Science",
      "Bengaluru",
      "Lightning Talk"
    ],
    "contents": "\nIntroduction\nThe PyCon India 2024 conference, held from September 20-23 at the NIMHANS Convention Center in Bengaluru, brought together a vibrant mix of sessions designed for learning, engagement, and networking. Attendees experienced a diverse lineup, including keynotes, technical talks, hands-on workshops, lightning talks, poster sessions, and open forums (birds of feather (BoF) sessions). Sponsor stalls added to the excitement, and the open spaces allowed for spontaneous interactions, adding to the conference’s lively atmosphere. Celebrating its 15th anniversary this year, PyCon India 2024 marked my second time attending, following my first experience at PyCon India 2023 in Hyderabad.\nLightning Talks\nI had the opportunity to present a Lightning Talk titled “Accelerating India’s Open Science Journey with Python.” In my session, I introduced the audience to the concept of open science, highlighting its importance for India, exploring its four foundational pillars, and demonstrating how Python plays a vital role in advancing open science efforts. The talk was well-received, and you can view the slides on Zenodo.\nKeynotes\nThe conference featured four insightful keynotes:\nKovid Goyal presented “Making Python Programs Fast,” where he shared in-depth techniques to optimize Python performance using C language.\nUsha Rengaraju spoke on “AI for Autism,” shedding light on neurodiversity and the potential of AI in autism research.\nMars Bar Lee explored “How Open-Source Opened My Opportunities,” highlighting how contributions to open-source projects can extend beyond code, such as her technical illustrations for NumPy.\nJames Powell delivered a creative talk, “How Many Oranges?”\nEach keynote brought valuable perspectives, and Mars Bar Lee’s emphasis on non-code contributions was particularly inspiring.\nWorkshops\nThe first day had 3-hour workshops going on in three tracks. I attended two immersive workshops:\nChat with Tables: Developing Q&A system on Tabular data using Code Generative LLMs by Abhijeet Kumar\nAbhijeet conducted a workshop about Generative AI powered by Large Language Models (LLMs) that are revolutionizing text, image, and video generation, as well as coding through enterprise solutions like GitHub Copilot, Google’s Gemini Code Assist, IBM’s Watsonx, and Amazon’s Q Developer. Abhijeet’s workshop focused on leveraging code-generating LLMs to enable non-technical users to generate Python code by using natural language queries, bridging the gap for business users who lack programming skills but need quick data insights. This solution is valuable for business users who often require ad-hoc analysis of tabular data but rely heavily on data teams. Abhijeet demonstrated a workflow to query tabular data, generate insights from CSVs, and enhance natural language querying (NLQ) through techniques like few-shot prompting, pruning, and validation. Additionally, the session included setting up a streamlined process for building Q&A systems for tabular data and creating a Streamlit app, making data insights more accessible to non-technical analysts.\nFrom Zero to Backend Hero: Creating Full-Featured Apps with FastAPI by Vivek Keshore\nVivek started by interacting with the audience to gather basic information like what an API is, the different types of APIs, and the various types of calls. Vivek discussed the benefits of using FastAPI. He went on to discuss database design. Vivek discussed about implementation of Pydantic models and the development of user management APIs.\nPyLadies Luncheon\nThe PyLadies Luncheon was a personal highlight during the conference. Women attendees gathered to share their experiences, openly discussing the challenges they face related to diversity and inclusivity in their workplaces and how they’ve overcome these obstacles over time. Hearing these stories and learning about the resilience and strategies of others was truly inspiring and energizing for me.\nSponsor Stalls\nThe conference featured several sponsor stalls, and one that stood out to me was the National Payments Corporation of India (NPCI), an umbrella organization for retail payments and settlement systems in India. I was intrigued to learn how their payments ecosystem is entirely open-source, with data storage managed on-premises instead of on Cloud platforms. Additionally, they introduced me to UPI payments that can be made via phone call or SMS, allowing transactions without an internet connection.\nDevSprints\nThe DevSprint was a one-day event featuring around 20 different projects. The day began with core contributors providing an overview of their respective projects, allowing participants to choose any project they were interested in contributing to. Among the various projects, I found myself particularly drawn to Django and NumPy.\nI opted to join the NumPy DevSprint, facilitated by technical illustrator Mars Bar Lee and NumPy core contributor Sebastian Berg. They introduced all the contributors to the NumPy project, outlining various ways to engage with the community through community calls, mailing lists, and comics, as well as how to contribute effectively. If you’re interested in contributing to NumPy, you can refer to the Contributing Guidelines for more information.\nI had the opportunity to attend an open session led by Saptak S., where participants discussed the nuances of digital accessibility, particularly in website development. The discussion covered essential points such as ensuring adequate contrast between text and background colors, structuring headings (H1, H2, H3, etc.) correctly, and guidelines for including appropriate details in the alt text for images. I discovered several valuable online resources to check and test webpage accessibility, including:\nA11y Project: A checklist for assessing accessibility levels.\naxe DevTools: A tool that evaluates whether a website complies with accessibility guidelines, available as an extension for Chrome, Firefox, and MS Edge browsers.\nWAVE: A tool that highlights areas of a website that are well or poorly designed regarding accessibility. WAVE also offers extensions for Chrome, Firefox, and MS Edge browsers.\nThe Button Cheat Sheet: A resource to determine if buttons on a website’s UI are designed effectively.\nThe WebAIM Million: The 2024 report on the accessibility of the top 1,000,000 home pages.\nWe discussed key considerations for developers when creating digitally accessible web pages. For instance, keyboard navigation is crucial for individuals with visual impairments or otherwise while working with a document by using only the keyboard, necessitating a logical heading structure (e.g., H1 followed by H2, and so on). It’s important to avoid jumping from say, H1 to H4, as this can confuse users.\nIn terms of coding practices, developers should specify the document language by adding the ‘lang’ attribute. This helps indicate which programming language is being used for different sections of the website. Additionally, tools like JAWS provide voice assistance to help developers ensure accessibility standards are met.\nDuring Continuous Integration (CI), it’s essential for developers to incorporate these accessibility guidelines into their workflows.\nSaptak also recommended several excellent learning resources, such as Adrian Roselli’s articles on accessibility issues, conference talks from experts in digital accessibility, and a helpful site for determining whether to use a carousel post: Should I Use a Carousel?\nConclusion\nThe PyCon India 2024 concluded with the DevSprints, marking an incredibly immersive learning experience for me. The Closing Ceremony featured two beat-boxers who entertained us, adding a refreshing twist to the event. I also had the pleasure of meeting Tanvi Agarwal, a digital illustrator who provides live transcription of talks, which I found truly inspiring. A big thank you to the entire PyCon India volunteer organizing team for once again delivering a fantastic conference!\nGet In Touch:\nGmail: bhogaljyoti1@gmail.comLinkedIn: http://www.linkedin.com/in/jyoti-bhogalGitHub: https://github.com/jyoti-bhogalWebsite: https://jyoti-bhogal.github.io/about-me/index.html\n\n\n\n",
    "preview": {},
    "last_modified": "2024-10-30T01:13:41+05:30",
    "input_file": "pycon_india_2024_blog.knit.md"
  },
  {
    "path": "blog/PuneFOSS_2.0/",
    "title": "PuneFOSS 2.0: A Dive into Open Source Insights and Initiatives",
    "description": "In February 2024, I got the opportunity to participate in FOSS United's one day conference PuneFOSS 2.0. With this blog, the reader will come to know about FOSS in general, the talks at the conference, and my views.",
    "author": [
      {
        "name": "Jyoti Bhogal",
        "url": "https://jyoti-bhogal.github.io/about-me/"
      }
    ],
    "date": "2024-03-08",
    "categories": [
      "Open Source",
      "Community Building",
      "FOSS",
      "FOSS United",
      "Open Science",
      "Experience Blog"
    ],
    "contents": "\r\nOpen SourceIntroduction\r\nRecently, I had the privilege of attending PuneFOSS 2.0, a one-day conference hosted by the FOSS United community at College of Engineering Pune, India on 24th Feb 2024. The conference had an impressive lineup of speakers, including industry experts like Vishal Arya, Rahul Kulkarni, Rohaan Goswami, Faeka Ansari, Mohammed Ali Chherwalla, Pranay Narang, Praveen Kumar, and Siddharth Jha, culminating in a thought-provoking panel discussion. This blog highlights some key insights shared during the event.\r\nWhat is FOSS?\r\nFOSS, an acronym for Free and Open Source Software, embodies a software development philosophy centered on freedom and openness. The term ‘Free’ denotes users’ liberty to run, alter, and share the software, while ‘Open Source’ signifies that the software’s source code is available for users to inspect, modify, and contribute to its progress. FOSS promotes collaboration, transparency, user empowerment, and frequently leads to the creation of more secure and sustainable software projects. Notable instances include Linux, Blender, Chromium, Kubernetes, and Mozilla Firefox.\r\nWhy FOSS?\r\nFOSS provides users with the liberty to utilize, adapt, and share software based on their preferences. This empowerment extends to both individuals and organizations, granting them control over their tools. The accessibility of the source code enables users to examine the inner workings of the software. FOSS promotes a collaborative model in software development, with a global community of diverse developers contributing to the creation of stronger, more secure, and innovative software. Users retain the freedom to tailor FOSS to meet their specific needs.\r\nQuote from Mohammed Ali Chherawalla’s talk on ‘Building an Open Source Culture in Companies’ during PuneFOSS 2.0 on 24th Feb 2024, describing that Open source is not just about making code publicOpen Source in Government\r\nRahul Kulkarni shared his experiences through his talk on ‘How open source encounters shaped my career’. He highlighted that one should choose open source or enterprise solutions based on the problem to be solved. I particularly liked the insights he gave about the necessity of using open source solutions for building digital platforms to be used by the Government of a country for large scale initiatives which require reaching out to each and every citizen. For example, the digital systems of government issued identity cards in India for various purposes like the AADHAAR UIDAI system. The rationale for the same being that this approach reduces the vendor buy-in, and independence from the roadmaps & timelines of the Enterprise software companies. He explained the importance of Data Empowerment and Protection Architecture (DEPA), which is a secure consent-based data sharing framework to accelerate financial inclusion. Rahul highly recommeded the book ‘The Cathedral and the Bazaar’ by Eric S. Raymond, in which the author explores the contrasting approaches of closed, centralized development (the cathedral) and open, decentralized collaboration (the bazaar) in the world of software development.\r\nRoadmap to Contribute to Open Source content and community\r\nIn an impressive talk on ‘Noobernetes assembly! Sneak Peek into one of the largest Open Source project’, Faeka Ansari provided a comprehensive walkthrough on starting a journey into open source contribution in Kubernetes and growing on the pathway. Drawing from her own experiences, she detailed the contribution pathway and shared valuable insights gained from working with the global Kubernetes community.\r\nFOSS for Social Impact\r\nRohaan Goswami shared his lived experiences around entrepreneurship focusing on the topic ‘Human Centered Technology: Field Notes & Stories of Social Innovation using FOSS in 10+ countries’. Rohaan spoke about the human-centric approach taken towards health tech by his organization YCenter in Africa and India. He also shared the lessons he learnt from working on global projects as diverse as using AI to help Governments make better policy decisions in Africa, developing patient-centric innovations in HPV prevention & cancer care in Southeast Asian countries and creating agritech innovations to support farmers.\r\nPanel Discussion Highlights\r\nThe panel discussion delved into critical questions, such as the interpretation of ‘Free’ - whether in terms of usage or freedom of development. Panelists, including Rahul, Rohaan, Nikhil, and Chakshu, provided diverse perspectives. Nikhil emphasized the government’s reliance on open source for large-scale projects, while Chakshu highlighted the importance of open source documentation as a valuable learning resource.\r\nAddressing Disparity in Github Accounts vs Contributors\r\nOne significant challenge discussed was the vast difference between the number of Github accounts and active contributors in India. The panel suggested initiatives like Code4GovtTech as a countrywide Indian alternative to the global GSoC, and highlighted the role of Consent Manager in India, encouraging attendees to explore its documentation for further insights.\r\nPicture of Jyoti Bhogal, the author of this blog, standing next to the Conference Poster at the PuneFOSS 2.0 eventConclusion\r\nPuneFOSS 2.0 was a melting pot of ideas, experiences, and discussions surrounding the open source community.The event not only showcased the diversity of expertise but also addressed pertinent issues, fostering a collaborative spirit in the pursuit of advancing open source initiatives in India. Check out this page to know more details of event or watch the livestream here.\r\nI had a day full of intriguing discussions with the speakers regsarding problem solving and creating impact in daily life of the user being at the core of any project, and the tools being secondary. The event reinforced my belief in the power of community!\r\nWhat are your thoughts and experiences around the open source philosophy? Leave them in the comments or write back to me at bhogaljyoti1@gmail.com; I am happy to read and reply!\r\n\r\n\r\n\r\n",
    "preview": "blog/PuneFOSS_2.0/open_source_label.jpg",
    "last_modified": "2024-03-20T15:15:23+05:30",
    "input_file": {}
  },
  {
    "path": "blog/pale_blue_dot_sdg_climate_action/",
    "title": "How Can Data Visualization Help in Achieving Climate Action Sustainable Developemnt Goal?",
    "description": "Data Insights for Sustainable Development Goals",
    "author": [
      {
        "name": "Jyoti Bhogal",
        "url": "https://jyoti-bhogal.github.io/about-me/"
      }
    ],
    "date": "2023-12-09",
    "categories": [
      "Data visualization",
      "R",
      "Open Science",
      "Open Data",
      "Earth Observation Data",
      "NASA",
      "Geospatial",
      "Maps",
      "Sustainable Development Goal",
      "Climate Action"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n\r\nIntroduction\r\nTo foster a sustainable lifestyle globally, the United Nations has established the Sustainable Development Goals (SDGs), a comprehensive framework consisting of 17 targets set to be achieved by 2030. Each goal is accompanied by specific indicators crucial for determining progress and success.\r\nGoal 13: Climate Action\r\nWithin this framework, Goal 13: Climate Action emerges as a pivotal objective for urgently addressing climate change and its far-reaching impacts. Goal 13 is gauged through two vital indicators:\r\nThe number of countries reporting nationally determined contributions, long-term strategies, national adaptation plans, and adaptation communications to the United Nations Framework Convention on Climate Change secretariat.\r\nTotal greenhouse gas (GHG) emissions per year.\r\nFocus on Indicator 2\r\nThis blog post centers its analysis on Indicator 2, delving into the critical assessment of total GHG emissions per year.\r\nGreenhouse Gases Overview\r\nThe primary greenhouse gases (GHGs) encompass carbon dioxide (CO2), methane, nitrous oxide, ozone, chlorofluorocarbons, and water vapour. With CO2 constituting approximately 76% of total GHGs (Source: Inventory of U.S. Greenhouse Gas Emissions and Sinks 1990-2015, EPA, 2017), my analysis will hone in on the dynamics of carbon dioxide.\r\nData Source and Collection\r\nFor this analysis, I leveraged the NASA Earth Observation data, a publicly accessible resource catering to a diverse audience, including students, citizen scientists, researchers, academicians, and industries. Using Terminal commands, I downloaded 2616 data files. Each of these files represents a day from January 1, 2015, to February 28, 2022. These files store records of the Assimilated Dry-Air Column Average CO2 Daily Mean, indexed by latitude and longitude, and are formatted in a .netCDF file. The data download steps drew inspiration from a comprehensive Medium article by Haolin Xiong.\r\nData Analysis in RStudio\r\nWe used the 2616 .netCDF files, one file representing one day. Each file has the daily average value of CO2 stored in grid points formed by the 576 longitude and 361 latitude points. We extracted the data for CO2 present in the form of a matrix of dimension 576 rows and 361 columns. From this matrix, we computed the global average, global north average, and global south average value of CO2, for each day. Thus we created three different time series for these average values from 1 Jan 2015 to 28 Feb 2022. To go a step ahead, we also converted the CO2 gridded data into a raster object to create a world map.\r\nEssential R packages for this analysisHere’s a snippet of the codeData Plotting:\r\nTo create interactive time series plots in R, we used the ‘dygraph’ package. The interactive plot is such that, when the user points the cursor on the plot area, they can see the (x,y) coordinates, which are the date and average values from the three time series, respectively. The plot also has a time range selector at the bottom, using which the user can zoom in to see the time series values for a particular time period of interest. Besides, we used the raster object to look at the daily values of CO2 in each geographical region. Two such plots are given below. The working code is accessible from the Github repository jyoti-bhogal/data_visualization.\r\nVisualising CO2 Changes\r\nThe resultant maps offer a vivid representation of the evolving values of the Assimilated Dry-Air Column Average CO2 Daily Mean. These visual cues paint a detailed picture of how CO2 emissions have dynamically evolved across diverse geographical regions. Please look closely at the numerical range in the index at the right of the graphs. Notice how the average value changes from ~390 ppm in 2015 to ~418 ppm in 2022.\r\n\r\n\r\nJan 2015: Average CO2 LevelsFeb 2022: Average CO2 LevelsGoal 13 and Future Targets\r\nThe Goal 13 of SDGs envisions a 43% reduction in GHG emissions by 2030 starting from 2010, culminating in net-zero emissions by 2050. The above graphs as well as sources reveal CO2 levels of approximately 390 ppm in 2010 and 419 ppm in 2023 (Source: Carbon Dioxide | Vital Signs – Climate Change),i.e., a 7.5% increase as opposed to the 43% targeted decrease. Indicator 2, reflecting on total GHG emissions, seems to fall short of anticipated targets. Addressing this shortfall requires not only governmental policies but also individual contributions. Transitioning to green fuel vehicles, re-assessing agricultural practices like Stubble burning, increasing vegetation cover, and embracing recycling and reuse initiatives stand as actionable steps towards a sustainable future.\r\nSome Fun Insight: Seasonal Fluctuations\r\nDiving into the intricacies of annual CO2 fluctuations, we uncover the profound impact of seasonal cycles in photosynthesis. From the Northern Hemisphere spring, where plant growth absorbs CO2, to the autumn, marked by plant decomposition releasing CO2, a symphony of natural processes influences atmospheric CO2 levels. A parallel, albeit milder, pattern plays out in the Southern Hemisphere during opposing seasons.\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "blog/pale_blue_dot_sdg_climate_action/banner_climate_action.jpg",
    "last_modified": "2024-03-16T23:33:31+05:30",
    "input_file": {}
  }
]
